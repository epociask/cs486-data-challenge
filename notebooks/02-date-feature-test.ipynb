{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model performance with new feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib as plt \n",
    "from os import chdir\n",
    "chdir(\"../\")\n",
    "\n",
    "df = pd.read_csv(\"data/aggregated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preprocessing import drop_values, encode_cats, add_busy_feature\n",
    "cleaned_df = drop_values(df)\n",
    "cleaned_df = encode_cats(cleaned_df)\n",
    "cleaned_df = cleaned_df.dropna()\n",
    "reduced_df = cleaned_df.sample(20000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scripts.model_helpers import split_train_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference\n",
      "0 0.8106\n",
      "inference\n",
      "100 0.8082\n",
      "inference\n",
      "200 0.807\n",
      "inference\n",
      "300 0.802\n",
      "inference\n",
      "400 0.8202\n",
      "inference\n",
      "500 0.8118\n",
      "inference\n",
      "600 0.8102\n",
      "inference\n",
      "700 0.8058\n",
      "inference\n",
      "800 0.8094\n",
      "inference\n",
      "900 0.8102\n",
      "inference\n",
      "1000 0.807\n",
      "inference\n",
      "1100 0.8042\n",
      "inference\n",
      "1200 0.81\n",
      "inference\n",
      "1300 0.8108\n",
      "inference\n",
      "1400 0.807\n",
      "inference\n",
      "1500 0.8186\n",
      "inference\n",
      "1600 0.8148\n",
      "inference\n",
      "1700 0.8072\n",
      "inference\n",
      "1800 0.8062\n",
      "inference\n",
      "1900 0.8084\n",
      "inference\n",
      "2000 0.8108\n"
     ]
    }
   ],
   "source": [
    "## Tuning... optimizing script function cut off value \n",
    "for i in [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]:\n",
    "    reduced_df = add_busy_feature(reduced_df, 2727.75748502994 + i) \n",
    "    train_df = reduced_df.drop(columns=['FL_DATE'])\n",
    "    print(\"inference\")\n",
    "    pred, test_y = split_train_predict(train_df, RandomForestClassifier())\n",
    "    print(i, accuracy_score(pred, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "### Sweet spot appears to be when 400 is added to fl_dates value counts mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
