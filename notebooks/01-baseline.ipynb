{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's establish a baseline accuracy to work with and work off of for feature engineering and determining if a given feature would help or hurt performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in the data \n",
    "df = pd.read_csv(\"data/aggregated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>B6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>B6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>B6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>B6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>BTV</td>\n",
       "      <td>Burlington, VT</td>\n",
       "      <td>JFK</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_WEEK     FL_DATE UNIQUE_CARRIER  FL_NUM ORIGIN  \\\n",
       "0    2.0          6.0  2017-02-25             B6    28.0    MCO   \n",
       "1    2.0          7.0  2017-02-26             B6    28.0    MCO   \n",
       "2    2.0          1.0  2017-02-27             B6    28.0    MCO   \n",
       "3    2.0          2.0  2017-02-28             B6    28.0    MCO   \n",
       "4    2.0          3.0  2017-02-01             B6    33.0    BTV   \n",
       "\n",
       "  ORIGIN_CITY_NAME DEST DEST_CITY_NAME  CRS_DEP_TIME  ARR_DEL15  \\\n",
       "0      Orlando, FL  EWR     Newark, NJ        1000.0        0.0   \n",
       "1      Orlando, FL  EWR     Newark, NJ         739.0        0.0   \n",
       "2      Orlando, FL  EWR     Newark, NJ        1028.0        0.0   \n",
       "3      Orlando, FL  EWR     Newark, NJ         739.0        0.0   \n",
       "4   Burlington, VT  JFK   New York, NY        1907.0        0.0   \n",
       "\n",
       "   CRS_ELAPSED_TIME  DISTANCE  Unnamed: 13  \n",
       "0             156.0     937.0          NaN  \n",
       "1             153.0     937.0          NaN  \n",
       "2             158.0     937.0          NaN  \n",
       "3             153.0     937.0          NaN  \n",
       "4              90.0     266.0          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right off the bat, Unnamed: 13 looks like it should be dropped immediately since it seems to take on many null values \n",
    "### ORIGIN_CITY_NAME is essentially the same thing as ORIGIN, except less detailed since it only describes the city name itself while a single city can have multiple airports and wouldn't too informative as a feature for determing if a flight in-fact gets delayed, thus it's dropped, same can be said for DEST_CITY_NAME as well  \n",
    "### FL_NUMBER is also a value that should be dropped as it seems incredibly cryptic and vague "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTH                     0\n",
       "DAY_OF_WEEK               0\n",
       "FL_DATE                   0\n",
       "UNIQUE_CARRIER            0\n",
       "FL_NUM                    0\n",
       "ORIGIN                    0\n",
       "ORIGIN_CITY_NAME          0\n",
       "DEST                      0\n",
       "DEST_CITY_NAME            0\n",
       "CRS_DEP_TIME              0\n",
       "ARR_DEL15             71020\n",
       "CRS_ELAPSED_TIME         10\n",
       "DISTANCE                  0\n",
       "Unnamed: 13         5129354\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "### Hmmm 5,129,354 NULL columns for Unnamed: 13, it should most certainly be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions for dropping irrelevant columns and encoding categorical values \n",
    "## For function details, see `/scripts/preprocessing.py`\n",
    "from scripts.preprocessing import drop_values\n",
    "from scripts.preprocessing import encode_cats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = drop_values(df)\n",
    "cleaned_df = encode_cats(cleaned_df)\n",
    "cleaned_df = cleaned_df.drop(columns=['FL_DATE'])\n",
    "cleaned_df = cleaned_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train, test, split, predict \n",
    "## Establishing baseline accuracy \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scripts.model_helpers import split_train_predict\n",
    "pred, test_y = split_train_predict(cleaned_df, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Baseline accuracy --->  0.7761746155257381\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"-\"*6)\n",
    "print(\"Baseline accuracy ---> \", accuracy_score(pred, test_y))\n",
    "print(\"-\"*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lovely, so 77.6% is now our baseline, let's perform some augmentations step-by-step and see if we can improve this baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
